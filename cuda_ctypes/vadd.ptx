//
// Generated by LLVM NVPTX Back-End
//

.version 7.3
.target sm_70
.address_size 64

// .globl	_add

// export the symbol
.visible .entry _add(
	// parameters are accessible via ld.param and st.param
	.param .u64 _add_param_0,
	.param .u64 _add_param_1,
	.param .u64 _add_param_2,
	.param .u32 _add_param_3
)
.maxntid 128, 1, 1
{
	// 32-bit register storage locations
	// excess will spill into memory
	// For each arch, there is a recommended max number of registers to use
	// Table 15 in the CUDA Programming Guide
	// For example, for sm_70:
	// Max registers per block: 64K
	// Max registers per thread: 255
	.reg .pred 	%p<5>;  // 1-bit predicate, false if zero, true otherwise
	.reg .f32 	%f<25>;  // 32-bit floating point
	.reg .b32 	%r<23>;  // 32 bits (untyped)
	.reg .b64 	%rd<10>;  // 64 bits (untyped)

	// load values from addresses passed in as parameters
	// apparently they contain addresses of those values?
	// we have to load from those addresses to get the values,
	// which are themselves addresses (pointers) to the vectors
	ld.param.u64 	%rd5, [_add_param_0];
	ld.param.u64 	%rd6, [_add_param_1];
	ld.param.u64 	%rd7, [_add_param_2];
	ld.param.u32 	%r18, [_add_param_3];

	mov.u32 	%r17, %tid.x;
	shl.b32 	%r19, %r17, 2;
	mov.u32 	%r20, %ctaid.x;
	mad.lo.s32 	%r21, %r20, 1024, %r19;
	add.s32 	%r22, %r21, 512;
	setp.lt.s32 	%p1, %r21, %r18;
	setp.lt.s32 	%p2, %r22, %r18;
	mul.wide.s32 	%rd8, %r21, 4;
	add.s64 	%rd1, %rd5, %rd8;

	@%p1 ld.global.cg.v4.b32 {%r1,%r2,%r3,%r4}, [ %rd1 + 0];
	mov.b32 	%f1, %r1;
	mov.b32 	%f2, %r2;
	mov.b32 	%f3, %r3;
	mov.b32 	%f4, %r4;

	@%p2 ld.global.cg.v4.b32 {%r5,%r6,%r7,%r8}, [ %rd1 + 2048];
	mov.b32 	%f5, %r5;
	mov.b32 	%f6, %r6;
	mov.b32 	%f7, %r7;
	mov.b32 	%f8, %r8;
	add.s64 	%rd3, %rd6, %rd8;

	@%p1 ld.global.cg.v4.b32 {%r9,%r10,%r11,%r12}, [ %rd3 + 0];
	mov.b32 	%f9, %r9;
	mov.b32 	%f10, %r10;
	mov.b32 	%f11, %r11;
	mov.b32 	%f12, %r12;

	@%p2 ld.global.cg.v4.b32 {%r13,%r14,%r15,%r16}, [ %rd3 + 2048];
	mov.b32 	%f13, %r13;
	mov.b32 	%f14, %r14;
	mov.b32 	%f15, %r15;
	mov.b32 	%f16, %r16;
    
    // vector add
	add.f32 	%f17, %f1, %f9;
	add.f32 	%f18, %f2, %f10;
	add.f32 	%f19, %f3, %f11;
	add.f32 	%f20, %f4, %f12;
	add.f32 	%f21, %f5, %f13;
	add.f32 	%f22, %f6, %f14;
	add.f32 	%f23, %f7, %f15;
	add.f32 	%f24, %f8, %f16;
    // compute target location
	add.s64 	%rd9, %rd7, %rd8;
	// save results
	st.global.v4.f32 	[%rd9], {%f17, %f18, %f19, %f20};
	st.global.v4.f32 	[%rd9+2048], {%f21, %f22, %f23, %f24};
	// return
	ret;
}

